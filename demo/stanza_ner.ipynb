{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 47892\r\n",
      "drwxr-xr-x 2 captain captain     4096 июн  5 13:46 .\r\n",
      "drwxr-xr-x 3 captain captain     4096 июн  5 13:12 ..\r\n",
      "-rw-r--r-- 1 captain captain 49030689 июн  5 14:32 ru_pampers_nertagger.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all ../saved_models/ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 8.00MB/s]                    \n",
      "2020-06-05 15:40:12 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2020-06-05 15:40:13 INFO: File exists: /home/captain/stanza_resources/ru/default.zip.\n",
      "2020-06-05 15:40:18 INFO: Finished downloading models and saved to /home/captain/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-08 13:38:21 INFO: Loading these models for language: ru (Russian):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | syntagrus               |\n",
      "| ner       | ../saved_m...rtagger.pt |\n",
      "=======================================\n",
      "\n",
      "2020-06-08 13:38:21 INFO: Use device: gpu\n",
      "2020-06-08 13:38:21 INFO: Loading: tokenize\n",
      "2020-06-08 13:38:21 INFO: Loading: ner\n",
      "2020-06-08 13:38:23 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('ru', processors='tokenize,ner', tokenize_pretokenized=True, ner_model_path=\"../saved_models/ner/ru_pampers_nertagger.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 256,\n",
       " 'char_hidden_dim': 100,\n",
       " 'word_emb_dim': 100,\n",
       " 'char_emb_dim': 100,\n",
       " 'num_layers': 1,\n",
       " 'char_num_layers': 1,\n",
       " 'pretrain_max_vocab': 100000,\n",
       " 'word_dropout': 0,\n",
       " 'locked_dropout': 0.0,\n",
       " 'dropout': 0.5,\n",
       " 'rec_dropout': 0,\n",
       " 'char_rec_dropout': 0,\n",
       " 'char_dropout': 0,\n",
       " 'char': True,\n",
       " 'charlm': False,\n",
       " 'charlm_shorthand': None,\n",
       " 'char_lowercase': False,\n",
       " 'lowercase': True,\n",
       " 'emb_finetune': True,\n",
       " 'input_transform': True,\n",
       " 'scheme': 'bioes',\n",
       " 'sample_train': 1.0,\n",
       " 'optim': 'sgd',\n",
       " 'lr': 0.1,\n",
       " 'min_lr': 0.0001,\n",
       " 'momentum': 0,\n",
       " 'lr_decay': 0.5,\n",
       " 'patience': 3,\n",
       " 'max_steps': 200000,\n",
       " 'eval_interval': 500,\n",
       " 'batch_size': 32,\n",
       " 'max_grad_norm': 5.0,\n",
       " 'log_step': 20,\n",
       " 'seed': 1234,\n",
       " 'model_path': '../saved_models/ner/ru_pampers_nertagger.pt',\n",
       " 'forward_charlm_path': '/home/captain/stanza_resources/ru/forward_charlm/newswiki.pt',\n",
       " 'backward_charlm_path': '/home/captain/stanza_resources/ru/backward_charlm/newswiki.pt',\n",
       " 'lang': 'ru',\n",
       " 'mode': 'predict'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.loaded_processors[1].pipeline.processors[\"ner\"].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_path': '/home/captain/stanza_resources/ru/tokenize/syntagrus.pt', 'pretokenized': True, 'lang': 'ru', 'mode': 'predict'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.loaded_processors[1].pipeline.processors[\"tokenize\"].config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Подгузники-трусики\ttype: PRODUCT\n",
      "entity: Bella\ttype: ORG\n",
      "entity: baby\ttype: ORG\n",
      "entity: Happy\ttype: ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Подгузники-трусики Bella baby Happy\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.models.ner.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Подгузники-трусики\ttype: PRODUCT\n",
      "entity: Bella\ttype: ORG\n",
      "entity: baby\ttype: ORG\n",
      "entity: Happy\ttype: ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Подгузники-трусики Bella baby Happy\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Трусики-подгузники\ttype: PRODUCT\n",
      "entity: PAMPERS\ttype: ORG\n",
      "entity: 2-3кг\ttype: QUANTITY\n",
      "entity: 28шт\ttype: CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Трусики-подгузники PAMPERS 2-3кг 28шт\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PRODUCT', 'PRODUCT', 'ORG', 'CARDINAL', 'CARDINAL'],\n",
       " ['Влажные', 'салфетки', 'Bella', '208', 'шт'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(line):\n",
    "    doc = nlp(line)\n",
    "    labels = [ent.type for sent in doc.sentences for ent in sent.ents]\n",
    "    text = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    return (labels, text)\n",
    "predict(\"Влажные салфетки Bella Sensitive, детские, 208 шт\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### получить данные как остальные классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "def calculate_match(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)):\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### прочитать валидационный корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Huggies', 'ORG'),\n",
       "  ('Подгузники', 'PRODUCT'),\n",
       "  ('Elite', 'MODEL'),\n",
       "  ('Soft', 'MODEL'),\n",
       "  ('12-22', 'QUANTITY'),\n",
       "  ('кг', 'QUANTITY'),\n",
       "  ('(', 'O'),\n",
       "  ('размер', 'ORDINAL'),\n",
       "  ('5', 'ORDINAL'),\n",
       "  (')', 'O'),\n",
       "  ('112', 'CARDINAL'),\n",
       "  ('шт', 'CARDINAL'),\n",
       "  ('Уцененный', 'O'),\n",
       "  ('товар', 'O'),\n",
       "  ('(№12)', 'O')],\n",
       " [('\"OONIES', 'ORG'),\n",
       "  ('Подгузники', 'PRODUCT'),\n",
       "  (',', 'O'),\n",
       "  ('размер', 'ORDINAL'),\n",
       "  ('S', 'ORDINAL'),\n",
       "  ('(', 'O'),\n",
       "  ('3-7', 'QUANTITY'),\n",
       "  ('кг', 'QUANTITY'),\n",
       "  ('),', 'O'),\n",
       "  ('72', 'CARDINAL'),\n",
       "  ('шт', 'CARDINAL'),\n",
       "  ('.(JOONIES?BUEBCHEN', 'O'),\n",
       "  ('новые', 'O'),\n",
       "  ('соски', 'O'),\n",
       "  ('и', 'O'),\n",
       "  ('бутылочки\"', 'O')]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_path=\"../data/ner/Russian-pampers/test.bio\"\n",
    "test_dataset = []\n",
    "with open(valid_df_path, \"r\") as fp:\n",
    "    acc = []\n",
    "    for line in fp:\n",
    "        if (line != \"\\n\"):\n",
    "            tmp = line.strip().split(\"\\t\")\n",
    "            acc.append((tmp[0], tmp[1]))\n",
    "        else:\n",
    "            test_dataset.append(acc)\n",
    "            acc = []\n",
    "test_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ORG', 'PRODUCT', 'MODEL', 'MODEL', 'QUANTITY', 'QUANTITY', 'O', 'ORDINAL', 'ORDINAL', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O'], ['ORG', 'PRODUCT', 'O', 'ORDINAL', 'ORDINAL', 'O', 'QUANTITY', 'QUANTITY', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O', 'O', 'O']]\n",
      "['Huggies Подгузники Elite Soft 12-22 кг ( размер 5 ) 112 шт Уцененный товар (№12)', '\"OONIES Подгузники , размер S ( 3-7 кг ), 72 шт .(JOONIES?BUEBCHEN новые соски и бутылочки\"']\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "test_texts = []\n",
    "for line in test_dataset:\n",
    "    test_labels.append(list(map(lambda x: x[1], line)))\n",
    "    test_texts.append(\" \".join(map(lambda x: x[0], line)))\n",
    "    \n",
    "print(test_labels[:2])\n",
    "print(test_texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2103"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### сохранить в файл транзакции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/pampers_test.tsv\", \"w+\") as fo:\n",
    "    for line in test_texts:\n",
    "        fo.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huggies Подгузники Elite Soft 12-22 кг ( размер 5 ) 112 шт Уцененный товар (№12)\r\n",
      "\"OONIES Подгузники , размер S ( 3-7 кг ), 72 шт .(JOONIES?BUEBCHEN новые соски и бутылочки\"\r\n",
      "Бамбуковые трусики Ракета на голубом (классика)\r\n",
      "Merries Подгузники-трусики M 6-11 кг 58 шт 3 упаковки Уцененный товар (№23)\r\n",
      "Многоразовый подгузник Чудо-чадо Пеленка-подгузник ситцевый\r\n",
      "iD Подгузники для взрослых Slip M 30 шт\r\n",
      "\" Seni Подгузники для взрослых ' Super Seni Plus ', размер 3 ( 100-150 см ), 30 шт \"\r\n",
      "Wet Wipes Pampers Sensitive 224 pcs\r\n",
      "Johnson`s baby От макушки до пяточек Влажные салфетки детские 15 шт\r\n",
      "\" Детские пеленки Helen Harper Soft&Dry 40*60 , ПРОМО, 30 шт 1401601\"\r\n"
     ]
    }
   ],
   "source": [
    "!head /tmp/pampers_test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### получить предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 37.7 ms, total: 14.8 s\n",
      "Wall time: 14.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15891"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred_labels = []\n",
    "pred_text =[]\n",
    "for line in test_texts:\n",
    "    tmp = predict(line)\n",
    "    pred_labels.append(tmp[0])\n",
    "    pred_text.append(tmp[1])\n",
    "    \n",
    "len([item for sublist in pred_labels for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)/15 # скорость порядка 140 транзакций в секунду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\tPrecision\tRecall\tF1\tTruePositive\tFalsePositiv\tFalseNegative\n",
      "ORDINAL\t\t0.957\t\t0.956\t0.956\t2047\t\t93\t\t94\n",
      "ORG\t\t0.955\t\t0.966\t0.960\t2134\t\t101\t\t75\n",
      "PRODUCT\t\t0.975\t\t0.972\t0.974\t3458\t\t87\t\t100\n",
      "MODEL\t\t0.951\t\t0.925\t0.938\t1499\t\t77\t\t122\n",
      "QUANTITY\t\t0.969\t\t0.960\t0.964\t2836\t\t91\t\t119\n"
     ]
    }
   ],
   "source": [
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "for y_test_l, y_pred_l in zip(test_labels, pred_labels):\n",
    "    calculate_match(y_test_l, y_pred_l)\n",
    "    \n",
    "labels=[\"ORDINAL\", \"ORG\", \"PRODUCT\", \"MODEL\", \"QUANTITY\"]\n",
    "print(\"Label\\tPrecision\\tRecall\\tF1\\tTruePositive\\tFalsePositiv\\tFalseNegative\")\n",
    "for label in labels:\n",
    "    precision = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FP.get(label, 0))\n",
    "    recall = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FN.get(label, 0))\n",
    "    f1 = 2 * (precision*recall) / max((precision + recall),1)\n",
    "    print(\"%s\\t\\t%.3f\\t\\t%.3f\\t%.3f\\t%d\\t\\t%d\\t\\t%d\" % (label, precision, recall, f1, counter_TP.get(label, 0), counter_FP.get(label, 0), counter_FN.get(label, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_debug(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)): #stamza не показывает O\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            print (f\"{i}:{label} == {pred_value}\")\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            print(f\"{i}:{label} <> {pred_value}\")\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Бамбуковые', 'PRODUCT'), ('трусики', 'PRODUCT'), ('Ракета', 'O'), ('на', 'O'), ('голубом', 'O'), ('(классика)', 'O')]\n",
      "[('Бамбуковые', 'PRODUCT'), ('трусики', 'PRODUCT'), ('Ракета', 'ORG')]\n",
      "-------------------------------------------------------------------------\n",
      "0:PRODUCT == PRODUCT\n",
      "1:PRODUCT == PRODUCT\n",
      "-------------------------------------------------------------------------\n",
      "Label\t\tPrecision\tRecall\tF1\tTruePositive\tFalsePositiv\tFalseNegative\n",
      "ORDINAL\t\t0.000\t\t0.000\t0.000\t0\t\t0\t\t0\n",
      "ORG\t\t0.000\t\t0.000\t0.000\t0\t\t0\t\t0\n",
      "PRODUCT\t\t1.000\t\t1.000\t1.000\t2\t\t0\t\t0\n",
      "MODEL\t\t0.000\t\t0.000\t0.000\t0\t\t0\t\t0\n",
      "QUANTITY\t\t0.000\t\t0.000\t0.000\t0\t\t0\t\t0\n"
     ]
    }
   ],
   "source": [
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "index = 2 #11, 15\n",
    "print(test_dataset[index])\n",
    "print(list(zip(pred_text[index], pred_labels[index])))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "calculate_match_debug(test_labels[index], pred_labels[index])\n",
    "labels=[\"ORDINAL\", \"ORG\", \"PRODUCT\", \"MODEL\", \"QUANTITY\"]\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Label\\t\\tPrecision\\tRecall\\tF1\\tTruePositive\\tFalsePositiv\\tFalseNegative\")\n",
    "for label in labels:\n",
    "    precision = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FP.get(label, 0))\n",
    "    recall = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FN.get(label, 0))\n",
    "    f1 = 2 * (precision*recall) / max((precision + recall),1)\n",
    "    print(\"%s\\t\\t%.3f\\t\\t%.3f\\t%.3f\\t%d\\t\\t%d\\t\\t%d\" % (label, precision, recall, f1, counter_TP.get(label, 0), counter_FP.get(label, 0), counter_FN.get(label, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ORG', 'PRODUCT', 'MODEL', 'MODEL', 'QUANTITY', 'QUANTITY', 'O', 'ORDINAL', 'ORDINAL', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O'], ['ORG', 'PRODUCT', 'O', 'ORDINAL', 'ORDINAL', 'O', 'QUANTITY', 'QUANTITY', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O', 'O', 'O'], ['PRODUCT', 'PRODUCT', 'O', 'O', 'O', 'O'], ['ORG', 'PRODUCT', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O'], ['PRODUCT', 'PRODUCT', 'ORG', 'PRODUCT', 'O'], ['ORG', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'MODEL', 'ORDINAL', 'CARDINAL', 'CARDINAL'], ['O', 'ORG', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'O', 'MODEL', 'MODEL', 'MODEL', 'O', 'ORDINAL', 'ORDINAL', 'O', 'QUANTITY', 'QUANTITY', 'O', 'CARDINAL', 'CARDINAL', 'O'], ['PRODUCT', 'PRODUCT', 'ORG', 'MODEL', 'CARDINAL', 'CARDINAL'], ['ORG', 'ORG', 'O', 'O', 'O', 'O', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'CARDINAL', 'CARDINAL'], ['O', 'PRODUCT', 'PRODUCT', 'ORG', 'ORG', 'MODEL', 'QUANTITY', 'O', 'O', 'CARDINAL', 'CARDINAL', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ORG', 'PRODUCT', 'MODEL', 'MODEL', 'QUANTITY', 'QUANTITY', 'ORDINAL', 'ORDINAL', 'CARDINAL', 'CARDINAL'], ['ORG', 'PRODUCT', 'ORDINAL', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT', 'ORG'], ['ORG', 'PRODUCT', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT', 'ORG', 'PRODUCT'], ['PRODUCT', 'PRODUCT', 'PRODUCT', 'ORG', 'ORDINAL', 'CARDINAL', 'CARDINAL'], ['ORG', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'MODEL', 'MODEL', 'MODEL', 'ORDINAL', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT', 'ORG', 'MODEL', 'CARDINAL', 'CARDINAL'], ['ORG', 'ORG', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT', 'ORG', 'ORG', 'MODEL', 'QUANTITY', 'CARDINAL', 'CARDINAL']]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
