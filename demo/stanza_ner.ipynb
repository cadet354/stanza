{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -all ../saved_models/ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 5.96MB/s]                    \n",
      "2020-06-06 11:55:48 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2020-06-06 11:55:49 INFO: File exists: /home/captain/stanza_resources/ru/default.zip.\n",
      "2020-06-06 11:55:54 INFO: Finished downloading models and saved to /home/captain/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-06 11:55:54 INFO: Loading these models for language: ru (Russian):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | syntagrus               |\n",
      "| ner       | ../saved_m...rtagger.pt |\n",
      "=======================================\n",
      "\n",
      "2020-06-06 11:55:54 INFO: Use device: cpu\n",
      "2020-06-06 11:55:54 INFO: Loading: tokenize\n",
      "2020-06-06 11:55:54 INFO: Loading: ner\n",
      "2020-06-06 11:55:55 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('ru', processors='tokenize,ner', tokenize_pretokenized=True, ner_model_path=\"../saved_models/ner/ru_pampers_nertagger.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp.loaded_processors[1].pipeline.processors[\"ner\"].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_path': '/home/captain/stanza_resources/ru/tokenize/syntagrus.pt', 'pretokenized': True, 'lang': 'ru', 'mode': 'predict'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.loaded_processors[1].pipeline.processors[\"tokenize\"].config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Подгузники-трусики\ttype: PRODUCT\n",
      "entity: Bella\ttype: ORG\n",
      "entity: baby\ttype: PRODUCT\n",
      "entity: Happy\ttype: PRODUCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Подгузники-трусики Bella baby Happy\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.models.ner.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Подгузники-трусики\ttype: PRODUCT\n",
      "entity: Bella\ttype: ORG\n",
      "entity: baby\ttype: PRODUCT\n",
      "entity: Happy\ttype: PRODUCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Подгузники-трусики Bella baby Happy\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Подгузники-трусики\ttype: PRODUCT\n",
      "entity: Bella\ttype: ORG\n",
      "entity: baby\ttype: PRODUCT\n",
      "entity: Happy\ttype: PRODUCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Подгузники-трусики Bella baby Happy\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Трусики-подгузники\ttype: PRODUCT\n",
      "entity: PAMPERS\ttype: ORG\n",
      "entity: 2-3кг\ttype: QUANTITY\n",
      "entity: 28шт\ttype: QUANTITY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Трусики-подгузники PAMPERS 2-3кг 28шт\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PRODUCT', 'PRODUCT', 'ORG', 'PRODUCT', 'PRODUCT', 'QUANTITY', 'QUANTITY'],\n",
       " ['Влажные', 'салфетки', 'Bella', 'Sensitive,', 'детские,', '208', 'шт'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(line):\n",
    "    doc = nlp(line)\n",
    "    labels = [ent.type for sent in doc.sentences for ent in sent.ents]\n",
    "    text = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    return (labels, text)\n",
    "predict(\"Влажные салфетки Bella Sensitive, детские, 208 шт\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### получить данные как остальные классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "def calculate_match(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)):\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### прочитать валидационный корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('text', 'labels'),\n",
       "  ('Подгузники', 'PRODUCT'),\n",
       "  ('Pampers', 'ORG'),\n",
       "  ('Procare', 'PRODUCT'),\n",
       "  ('1', 'ORDINAL'),\n",
       "  ('2-5кг', 'QUANTITY'),\n",
       "  ('38шт', 'QUANTITY')],\n",
       " [('Подгузники', 'PRODUCT'),\n",
       "  ('Pampers', 'ORG'),\n",
       "  ('Procare', 'PRODUCT'),\n",
       "  ('2', 'ORDINAL'),\n",
       "  ('3-6кг', 'QUANTITY'),\n",
       "  ('36шт', 'QUANTITY')]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_path=\"../data/ner/Russian-pampers/dev.bio\"\n",
    "test_dataset = []\n",
    "with open(valid_df_path, \"r\") as fp:\n",
    "    acc = []\n",
    "    for line in fp:\n",
    "        if (line != \"\\n\"):\n",
    "            tmp = line.strip().split(\"\\t\")\n",
    "            acc.append((tmp[0], tmp[1]))\n",
    "        else:\n",
    "            test_dataset.append(acc)\n",
    "            acc = []\n",
    "test_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['labels', 'PRODUCT', 'ORG', 'PRODUCT', 'ORDINAL', 'QUANTITY', 'QUANTITY'], ['PRODUCT', 'ORG', 'PRODUCT', 'ORDINAL', 'QUANTITY', 'QUANTITY']]\n",
      "['text Подгузники Pampers Procare 1 2-5кг 38шт', 'Подгузники Pampers Procare 2 3-6кг 36шт']\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "test_texts = []\n",
    "for line in test_dataset:\n",
    "    test_labels.append(list(map(lambda x: x[1], line)))\n",
    "    test_texts.append(\" \".join(map(lambda x: x[0], line)))\n",
    "    \n",
    "print(test_labels[:2])\n",
    "print(test_texts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### получить предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 s, sys: 1.92 ms, total: 4.65 s\n",
      "Wall time: 783 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred_labels = []\n",
    "pred_text =[]\n",
    "for line in test_texts:\n",
    "    tmp = predict(line)\n",
    "    pred_labels.append(tmp[0])\n",
    "    pred_text.append(tmp[1])\n",
    "    \n",
    "len([item for sublist in pred_labels for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\tPrecision\tRecall\tF1\tTruePositive\tFalsePositiv\tFalseNegative\n",
      "ORDINAL\t\t1.000\t\t0.944\t0.971\t51\t\t0\t\t3\n",
      "ORG\t\t1.000\t\t1.000\t1.000\t53\t\t0\t\t0\n",
      "PRODUCT\t\t1.000\t\t1.000\t1.000\t171\t\t0\t\t0\n",
      "QUANTITY\t\t0.980\t\t0.987\t0.983\t147\t\t3\t\t2\n"
     ]
    }
   ],
   "source": [
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "for y_test_l, y_pred_l in zip(test_labels, pred_labels):\n",
    "    calculate_match(y_test_l, y_pred_l)\n",
    "    \n",
    "labels=[\"ORDINAL\", \"ORG\", \"PRODUCT\", \"QUANTITY\"]\n",
    "print(\"Label\\tPrecision\\tRecall\\tF1\\tTruePositive\\tFalsePositiv\\tFalseNegative\")\n",
    "for label in labels:\n",
    "    precision = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FP.get(label, 0))\n",
    "    recall = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FN.get(label, 0))\n",
    "    f1 = 2 * (precision*recall) / max((precision + recall),1)\n",
    "    print(\"%s\\t\\t%.3f\\t\\t%.3f\\t%.3f\\t%d\\t\\t%d\\t\\t%d\" % (label, precision, recall, f1, counter_TP.get(label, 0), counter_FP.get(label, 0), counter_FN.get(label, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_debug(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)): #stamza не показывает O\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            print (f\"{i}:{label} == {pred_value}\")\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            print(f\"{i}:{label} <> {pred_value}\")\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Подгузники', 'PRODUCT'), ('Pampers', 'ORG'), ('Premium', 'PRODUCT'), ('Care', 'PRODUCT'), ('Midi', 'PRODUCT'), ('3', 'ORDINAL'), ('6-10кг', 'QUANTITY'), ('52шт', 'QUANTITY')]\n",
      "[('Подгузники', 'PRODUCT'), ('Pampers', 'ORG'), ('Premium', 'PRODUCT'), ('Care', 'PRODUCT'), ('Midi', 'PRODUCT'), ('3', 'ORDINAL'), ('6-10кг', 'QUANTITY'), ('52шт', 'QUANTITY')]\n",
      "-------------------------------------------------------------------------\n",
      "0:PRODUCT == PRODUCT\n",
      "1:ORG == ORG\n",
      "2:PRODUCT == PRODUCT\n",
      "3:PRODUCT == PRODUCT\n",
      "4:PRODUCT == PRODUCT\n",
      "5:ORDINAL == ORDINAL\n",
      "6:QUANTITY == QUANTITY\n",
      "7:QUANTITY == QUANTITY\n",
      "-------------------------------------------------------------------------\n",
      "Label\t\tPrecision\tRecall\tF1\tTruePositive\tFalsePositiv\tFalseNegative\n",
      "ORDINAL\t\t1.000\t\t1.000\t1.000\t1\t\t0\t\t0\n",
      "ORG\t\t1.000\t\t1.000\t1.000\t1\t\t0\t\t0\n",
      "PRODUCT\t\t1.000\t\t1.000\t1.000\t4\t\t0\t\t0\n",
      "QUANTITY\t\t1.000\t\t1.000\t1.000\t2\t\t0\t\t0\n"
     ]
    }
   ],
   "source": [
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "index = 20 #11, 15\n",
    "print(test_dataset[index])\n",
    "print(list(zip(pred_text[index], pred_labels[index])))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "calculate_match_debug(test_labels[index], pred_labels[index])\n",
    "labels=[\"ORDINAL\", \"ORG\", \"PRODUCT\", \"QUANTITY\"]\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Label\\t\\tPrecision\\tRecall\\tF1\\tTruePositive\\tFalsePositiv\\tFalseNegative\")\n",
    "for label in labels:\n",
    "    precision = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FP.get(label, 0))\n",
    "    recall = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FN.get(label, 0))\n",
    "    f1 = 2 * (precision*recall) / max((precision + recall),1)\n",
    "    print(\"%s\\t\\t%.3f\\t\\t%.3f\\t%.3f\\t%d\\t\\t%d\\t\\t%d\" % (label, precision, recall, f1, counter_TP.get(label, 0), counter_FP.get(label, 0), counter_FN.get(label, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
