{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 191648\r\n",
      "drwxr-xr-x 2 captain captain     4096 июн 26 01:07 .\r\n",
      "drwxr-xr-x 3 captain captain     4096 июн  5 13:12 ..\r\n",
      "-rw-r--r-- 1 captain captain 49059548 июн 16 19:56 ru_kasha_nertagger.pt\r\n",
      "-rw-r--r-- 1 captain captain 49061717 июн 26 01:30 ru_pampers_kasha_pure_nertagger.pt\r\n",
      "-rw-r--r-- 1 captain captain 49058278 июн  8 13:18 ru_pampers_nertagger.pt\r\n",
      "-rw-r--r-- 1 captain captain 49050374 июн 25 14:54 ru_pure_nertagger.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all ../saved_models/ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 6.00MB/s]                    \n",
      "2020-06-26 09:52:58 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2020-06-26 09:52:59 INFO: File exists: /home/captain/stanza_resources/ru/default.zip.\n",
      "2020-06-26 09:53:05 INFO: Finished downloading models and saved to /home/captain/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-26 09:53:05 INFO: Loading these models for language: ru (Russian):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | syntagrus               |\n",
      "| ner       | ../saved_m...rtagger.pt |\n",
      "=======================================\n",
      "\n",
      "2020-06-26 09:53:05 INFO: Use device: gpu\n",
      "2020-06-26 09:53:05 INFO: Loading: tokenize\n",
      "2020-06-26 09:53:05 INFO: Loading: ner\n",
      "2020-06-26 09:53:07 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('ru', processors='tokenize,ner', tokenize_pretokenized=True, ner_model_path=\"../saved_models/ner/ru_pampers_kasha_pure_nertagger.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_path': '/home/captain/stanza_resources/ru/tokenize/syntagrus.pt', 'pretokenized': True, 'lang': 'ru', 'mode': 'predict'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.loaded_processors[1].pipeline.processors[\"tokenize\"].config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Каша\ttype: PRODUCT\n",
      "entity: ФЛЕР\ttype: ORG\n",
      "entity: льняная\ttype: PRODUCT\n",
      "entity: кэробом\ttype: PRODUCT\n",
      "entity: кунжутом,\ttype: PRODUCT\n",
      "entity: 400\ttype: CARDINAL\n",
      "entity: г\ttype: CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Каша ФЛЕР\tльняная\tс\tкэробом\tи кунжутом,\t400\tг\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.models.ner.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['PRODUCT', 'ORG', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'CARDINAL', 'CARDINAL'], ['Каша', 'ФЛЕР', 'льняная', 'кэробом', 'кунжутом,', '400', 'г'])\n",
      "(['ORG', 'ORG', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'QUANTITY', 'QUANTITY', 'CARDINAL'], ['Фруто', 'Няня', 'пюре', 'десерт', 'вишни', 'рябины,яблока', 'смородины', '5', 'месяцев,90', 'г'])\n",
      "(['PRODUCT', 'PRODUCT', 'ORG', 'CARDINAL', 'CARDINAL'], ['Влажные', 'салфетки', 'Bella', '208', 'шт'])\n"
     ]
    }
   ],
   "source": [
    "def predict(line):\n",
    "    doc = nlp(line)\n",
    "    labels = [ent.type for sent in doc.sentences for ent in sent.ents]\n",
    "    text = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    return (labels, text)\n",
    "print(predict(\"Каша ФЛЕР\tльняная\tс\tкэробом\tи кунжутом,\t400\tг\"))\n",
    "print(predict(\"Фруто Няня пюре десерт из вишни рябины,яблока\tи смородины с 5 месяцев,90 г\"))\n",
    "print(predict(\"Влажные салфетки Bella Sensitive, детские, 208 шт\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### получить данные как остальные классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "def calculate_match(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)):\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### прочитать валидационный корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('\"', 'O'),\n",
       "  ('Халеда', 'ORG'),\n",
       "  ('пюре', 'PRODUCT'),\n",
       "  ('из', 'O'),\n",
       "  ('брокколи', 'PRODUCT'),\n",
       "  (',', 'O'),\n",
       "  ('с', 'O'),\n",
       "  ('4', 'QUANTITY'),\n",
       "  ('месяцев', 'QUANTITY'),\n",
       "  (',', 'O'),\n",
       "  ('90', 'CARDINAL'),\n",
       "  ('г', 'CARDINAL'),\n",
       "  ('\"', 'O')],\n",
       " [('\"', 'O'),\n",
       "  ('Hipp', 'ORG'),\n",
       "  ('пюре', 'PRODUCT'),\n",
       "  ('яблоко', 'PRODUCT'),\n",
       "  (',', 'O'),\n",
       "  ('банан', 'PRODUCT'),\n",
       "  (',', 'O'),\n",
       "  ('малина', 'PRODUCT'),\n",
       "  (',', 'O'),\n",
       "  ('злаки', 'PRODUCT'),\n",
       "  (\"'\", 'O')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# весь валидационный корпус\n",
    "valid_df_path=\"../data/ner/Russian-pampers_kasha_pure/test.bio\"\n",
    "test_dataset = []\n",
    "with open(valid_df_path, \"r\") as fp:\n",
    "    acc = []\n",
    "    for line in fp:\n",
    "        if (line != \"\\n\"):\n",
    "            tmp = line.strip().split(\"\\t\")\n",
    "            if len(tmp) != 2:\n",
    "                print(line)\n",
    "            acc.append((tmp[0], tmp[1]))\n",
    "        else:\n",
    "            test_dataset.append(acc)\n",
    "            acc = []\n",
    "\n",
    "test_dataset[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3138"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ORG', 'PRODUCT', 'MODEL', 'MODEL', 'QUANTITY', 'QUANTITY', 'O', 'ORDINAL', 'ORDINAL', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O'], ['ORG', 'PRODUCT', 'O', 'ORDINAL', 'ORDINAL', 'O', 'QUANTITY', 'QUANTITY', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O', 'O', 'O']]\n",
      "['Huggies Подгузники Elite Soft 12-22 кг ( размер 5 ) 112 шт Уцененный товар (№12)', '\"OONIES Подгузники , размер S ( 3-7 кг ), 72 шт .(JOONIES?BUEBCHEN новые соски и бутылочки\"']\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "test_texts = []\n",
    "for line in test_dataset:\n",
    "    test_labels.append(list(map(lambda x: x[1], line)))\n",
    "    test_texts.append(\" \".join(map(lambda x: x[0], line)))\n",
    "    \n",
    "print(test_labels[:2])\n",
    "print(test_texts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### сохранить в файл транзакции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/pampers_kasha_pure_test.tsv\", \"w+\") as fo:\n",
    "    for line in test_texts:\n",
    "        fo.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huggies Подгузники Elite Soft 12-22 кг ( размер 5 ) 112 шт Уцененный товар (№12)\r\n",
      "\"OONIES Подгузники , размер S ( 3-7 кг ), 72 шт .(JOONIES?BUEBCHEN новые соски и бутылочки\"\r\n",
      "Бамбуковые трусики Ракета на голубом (классика)\r\n",
      "Merries Подгузники-трусики M 6-11 кг 58 шт 3 упаковки Уцененный товар (№23)\r\n",
      "Многоразовый подгузник Чудо-чадо Пеленка-подгузник ситцевый\r\n",
      "iD Подгузники для взрослых Slip M 30 шт\r\n",
      "\" Seni Подгузники для взрослых ' Super Seni Plus ', размер 3 ( 100-150 см ), 30 шт \"\r\n",
      "Wet Wipes Pampers Sensitive 224 pcs\r\n",
      "Johnson`s baby От макушки до пяточек Влажные салфетки детские 15 шт\r\n",
      "\" Детские пеленки Helen Harper Soft&Dry 40*60 , ПРОМО, 30 шт 1401601\"\r\n"
     ]
    }
   ],
   "source": [
    "!head /tmp/pampers_kasha_pure_test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### получить предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 83.3 ms, total: 24 s\n",
      "Wall time: 24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23896"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred_labels = []\n",
    "pred_text =[]\n",
    "for line in test_texts:\n",
    "    tmp = predict(line)\n",
    "    pred_labels.append(tmp[0])\n",
    "    pred_text.append(tmp[1])\n",
    "    \n",
    "len([item for sublist in pred_labels for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)/24 # скорость порядка 130-140 транзакций в секунду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tPrecision\tRecall\tF1\tTruePositive\tFalsePositiv\tFalseNegative\n",
      "ORDINAL\t\t0.959\t\t0.960\t0.960\t2102\t\t90\t\t87\n",
      "ORG\t\t0.968\t\t0.965\t0.966\t3246\t\t109\t\t119\n",
      "MODEL\t\t0.944\t\t0.940\t0.942\t1672\t\t100\t\t107\n",
      "PRODUCT\t\t0.981\t\t0.978\t0.979\t6680\t\t130\t\t150\n",
      "QUANTITY\t\t0.971\t\t0.963\t0.967\t3871\t\t115\t\t148\n"
     ]
    }
   ],
   "source": [
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "for y_test_l, y_pred_l in zip(test_labels, pred_labels):\n",
    "    calculate_match(y_test_l, y_pred_l)\n",
    "    \n",
    "labels=[\"ORDINAL\", \"ORG\", \"MODEL\" ,\"PRODUCT\",  \"QUANTITY\"]\n",
    "print(\"Label\\t\\tPrecision\\tRecall\\tF1\\tTruePositive\\tFalsePositiv\\tFalseNegative\")\n",
    "for label in labels:\n",
    "    precision = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FP.get(label, 0))\n",
    "    recall = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FN.get(label, 0))\n",
    "    f1 = 2 * (precision*recall) / max((precision + recall),1)\n",
    "    print(\"%s\\t\\t%.3f\\t\\t%.3f\\t%.3f\\t%d\\t\\t%d\\t\\t%d\" % (label, precision, recall, f1, counter_TP.get(label, 0), counter_FP.get(label, 0), counter_FN.get(label, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "def find_model_mismatch(true_values, pred_values):\n",
    "    results = []\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)):\n",
    "        if label != \"MODEL\":\n",
    "            continue\n",
    "        if len(pred_values) <= i:\n",
    "            results.append(pred_values)\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i] \n",
    "        #print(\"true=%s pred_value=%s index=%d\" % (label, pred_value, i))\n",
    "        if  label != pred_value:\n",
    "            results.append(pred_value)\n",
    "    return results\n",
    "\n",
    "mismatch_results = []\n",
    "mismatch_index = []\n",
    "\n",
    "for index, (y_test_l, y_pred_l) in enumerate(zip(test_labels, pred_labels)):\n",
    "    tmp = find_model_mismatch(y_test_l, y_pred_l)\n",
    "    if len(tmp) > 0:\n",
    "        #print(index)\n",
    "        mismatch_results.extend(tmp)\n",
    "        mismatch_index.append(index)\n",
    "#     if index >9:\n",
    "#         break\n",
    "        \n",
    "print(len(mismatch_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 94, 139, 192, 210, 243, 265, 325, 332, 493, 557, 576]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_index[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1320, 1350, 1390, 1458, 1477, 1478, 1520, 1636, 1670, 1685, 1766, 1769]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_index[40:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2062, 2133, 2263, 2297, 2329, 2361, 2370, 2380, 2384, 2394, 2460, 2665]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_index[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_debug(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)): #stamza не показывает O\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            print (f\"{i}:{label} == {pred_value}\")\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            print(f\"{i}:{label} <> {pred_value}\")\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Подгузники Pampers New Baby ' Памперс Нью Бэби ' 2 Mini ( 3-6 кг ), 144 шт 1543907\"\n",
      "-------------------------------------------------------------------------\n",
      "[('Подгузники', 'PRODUCT'), ('Pampers', 'ORG'), ('New', 'MODEL'), ('Baby', 'MODEL'), ('Памперс', 'ORG'), ('Нью', 'MODEL'), ('Бэби', 'MODEL'), ('2', 'ORDINAL'), ('Mini', 'ORDINAL'), ('3-6', 'QUANTITY'), ('кг', 'QUANTITY'), ('144', 'CARDINAL'), ('шт', 'CARDINAL')]\n",
      "\n",
      "[('Подгузники', 'PRODUCT'), ('Pampers', 'ORG'), ('New', 'MODEL'), ('Baby', 'MODEL'), ('Нью', 'MODEL'), ('Бэби', 'MODEL'), ('2', 'ORDINAL'), ('Mini', 'ORDINAL'), ('3-6', 'QUANTITY'), ('кг', 'QUANTITY'), ('144', 'CARDINAL'), ('шт', 'CARDINAL')]\n",
      "-------------------------------------------------------------------------\n",
      "0:PRODUCT == PRODUCT\n",
      "1:ORG == ORG\n",
      "2:MODEL == MODEL\n",
      "3:MODEL == MODEL\n",
      "4:ORG <> MODEL\n",
      "5:MODEL == MODEL\n",
      "6:MODEL <> ORDINAL\n",
      "7:ORDINAL == ORDINAL\n",
      "8:ORDINAL <> QUANTITY\n",
      "9:QUANTITY == QUANTITY\n",
      "10:QUANTITY <> CARDINAL\n",
      "11:CARDINAL == CARDINAL\n"
     ]
    }
   ],
   "source": [
    "index = 1320\n",
    "print(test_texts[index])\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(list(filter(lambda tup: tup[1] != \"O\", test_dataset[index])))\n",
    "print()\n",
    "print(list(zip(pred_text[index], pred_labels[index])))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "calculate_match_debug(test_labels[index], pred_labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Трусики Qianquhui Самолет- L\n",
      "-------------------------------------------------------------------------\n",
      "[('Трусики', 'PRODUCT'), ('Qianquhui', 'ORG'), ('Самолет-', 'O'), ('L', 'ORDINAL')]\n",
      "\n",
      "[('Трусики', 'PRODUCT'), ('Qianquhui', 'ORG'), ('L', 'ORDINAL')]\n",
      "-------------------------------------------------------------------------\n",
      "0:PRODUCT == PRODUCT\n",
      "1:ORG == ORG\n",
      "2:ORDINAL == ORDINAL\n"
     ]
    }
   ],
   "source": [
    "index = 154\n",
    "print(test_texts[index])\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(test_dataset[index])\n",
    "print()\n",
    "print(list(zip(pred_text[index], pred_labels[index])))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "calculate_match_debug(test_labels[index], pred_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ORG', 'PRODUCT', 'MODEL', 'MODEL', 'QUANTITY', 'QUANTITY', 'O', 'ORDINAL', 'ORDINAL', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O'], ['ORG', 'PRODUCT', 'O', 'ORDINAL', 'ORDINAL', 'O', 'QUANTITY', 'QUANTITY', 'O', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O', 'O', 'O'], ['PRODUCT', 'PRODUCT', 'O', 'O', 'O', 'O'], ['ORG', 'PRODUCT', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL', 'CARDINAL', 'CARDINAL', 'O', 'O', 'O'], ['PRODUCT', 'PRODUCT', 'ORG', 'PRODUCT', 'O'], ['ORG', 'PRODUCT', 'O', 'PRODUCT', 'ORG', 'ORDINAL', 'CARDINAL', 'CARDINAL'], ['O', 'ORG', 'PRODUCT', 'O', 'PRODUCT', 'O', 'MODEL', 'MODEL', 'MODEL', 'O', 'ORDINAL', 'ORDINAL', 'O', 'QUANTITY', 'QUANTITY', 'O', 'CARDINAL', 'CARDINAL', 'O'], ['PRODUCT', 'PRODUCT', 'ORG', 'MODEL', 'CARDINAL', 'CARDINAL'], ['ORG', 'ORG', 'O', 'O', 'O', 'O', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'CARDINAL', 'CARDINAL'], ['O', 'PRODUCT', 'PRODUCT', 'ORG', 'ORG', 'MODEL', 'QUANTITY', 'O', 'O', 'CARDINAL', 'CARDINAL', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ORG', 'PRODUCT', 'MODEL', 'MODEL', 'QUANTITY', 'QUANTITY', 'ORDINAL', 'ORDINAL', 'CARDINAL', 'CARDINAL'], ['ORG', 'PRODUCT', 'ORDINAL', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT'], ['ORG', 'PRODUCT', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT', 'ORG', 'PRODUCT'], ['ORG', 'PRODUCT', 'PRODUCT', 'ORG', 'ORDINAL', 'CARDINAL', 'CARDINAL'], ['ORG', 'PRODUCT', 'PRODUCT', 'MODEL', 'MODEL', 'MODEL', 'ORDINAL', 'ORDINAL', 'QUANTITY', 'QUANTITY', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT', 'ORG', 'MODEL', 'CARDINAL', 'CARDINAL'], ['ORG', 'ORG', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'CARDINAL', 'CARDINAL'], ['PRODUCT', 'PRODUCT', 'ORG', 'ORG', 'MODEL', 'QUANTITY', 'CARDINAL', 'CARDINAL']]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
