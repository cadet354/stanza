{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 95832\r\n",
      "drwxr-xr-x 2 captain captain     4096 июн 16 13:46 .\r\n",
      "drwxr-xr-x 3 captain captain     4096 июн  5 13:12 ..\r\n",
      "-rw-r--r-- 1 captain captain 49059548 июн 16 19:56 ru_kasha_nertagger.pt\r\n",
      "-rw-r--r-- 1 captain captain 49058278 июн  8 13:18 ru_pampers_nertagger.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all ../saved_models/ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 5.03MB/s]                    \n",
      "2020-06-16 20:49:34 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2020-06-16 20:49:35 INFO: File exists: /home/captain/stanza_resources/ru/default.zip.\n",
      "2020-06-16 20:49:41 INFO: Finished downloading models and saved to /home/captain/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 20:49:45 INFO: Loading these models for language: ru (Russian):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | syntagrus               |\n",
      "| ner       | ../saved_m...rtagger.pt |\n",
      "=======================================\n",
      "\n",
      "2020-06-16 20:49:45 INFO: Use device: gpu\n",
      "2020-06-16 20:49:45 INFO: Loading: tokenize\n",
      "2020-06-16 20:49:45 INFO: Loading: ner\n",
      "2020-06-16 20:49:47 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('ru', processors='tokenize,ner', tokenize_pretokenized=True, ner_model_path=\"../saved_models/ner/ru_kasha_nertagger.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_path': '/home/captain/stanza_resources/ru/tokenize/syntagrus.pt', 'pretokenized': True, 'lang': 'ru', 'mode': 'predict'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.loaded_processors[1].pipeline.processors[\"tokenize\"].config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Каша\ttype: PRODUCT\n",
      "entity: ФЛЕР\ttype: ORG\n",
      "entity: льняная\ttype: PRODUCT\n",
      "entity: с\ttype: PRODUCT\n",
      "entity: кэробом\ttype: PRODUCT\n",
      "entity: и\ttype: PRODUCT\n",
      "entity: кунжутом,\ttype: PRODUCT\n",
      "entity: 400\ttype: CARDINAL\n",
      "entity: г\ttype: CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Каша ФЛЕР\tльняная\tс\tкэробом\tи кунжутом,\t400\tг\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.models.ner.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PRODUCT',\n",
       "  'ORG',\n",
       "  'PRODUCT',\n",
       "  'PRODUCT',\n",
       "  'PRODUCT',\n",
       "  'PRODUCT',\n",
       "  'PRODUCT',\n",
       "  'CARDINAL',\n",
       "  'CARDINAL'],\n",
       " ['Каша', 'ФЛЕР', 'льняная', 'с', 'кэробом', 'и', 'кунжутом,', '400', 'г'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(line):\n",
    "    doc = nlp(line)\n",
    "    labels = [ent.type for sent in doc.sentences for ent in sent.ents]\n",
    "    text = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    return (labels, text)\n",
    "predict(\"Каша ФЛЕР\tльняная\tс\tкэробом\tи кунжутом,\t400\tг\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### получить данные как остальные классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "def calculate_match(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)):\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### прочитать валидационный корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ПОДГУЗ-ТРУС', 'PRODUCT'),\n",
       "  ('PAMPERS', 'ORG'),\n",
       "  ('А.Б', 'MODEL'),\n",
       "  ('МАКСИ', 'ORDINAL'),\n",
       "  ('8-14', 'QUANTITY'),\n",
       "  ('104ШТ', 'CARDINAL')],\n",
       " [('ПОДГУЗ', 'PRODUCT'),\n",
       "  ('PAMPERS', 'ORG'),\n",
       "  ('АКТ.Б', 'MODEL'),\n",
       "  ('МАКСИ', 'ORDINAL'),\n",
       "  ('9-14КГ', 'QUANTITY'),\n",
       "  ('132ШТ', 'CARDINAL')]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отдельно каши\n",
    "valid_df_path=\"../data/ner/Russian-kasha/test.bio\"\n",
    "test_dataset = []\n",
    "with open(valid_df_path, \"r\") as fp:\n",
    "    acc = []\n",
    "    for line in fp:\n",
    "        if (line != \"\\n\"):\n",
    "            tmp = line.strip().split(\"\\t\")\n",
    "            acc.append((tmp[0], tmp[1]))\n",
    "        else:\n",
    "            test_dataset.append(acc)\n",
    "            acc = []\n",
    "# отдельно памперсы\n",
    "valid_df_path=\"../data/ner/Russian-pampers/test.bio\"\n",
    "with open(valid_df_path, \"r\") as fp:\n",
    "    acc = []\n",
    "    for line in fp:\n",
    "        if (line != \"\\n\"):\n",
    "            tmp = line.strip().split(\"\\t\")\n",
    "            acc.append((tmp[0], tmp[1]))\n",
    "        else:\n",
    "            test_dataset.append(acc)\n",
    "            acc = []\n",
    "test_dataset[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2398"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'ORG', 'O', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'O', 'CARDINAL', 'CARDINAL', 'CARDINAL', 'O', 'O', 'CARDINAL', 'O'], ['PRODUCT', 'PRODUCT', 'PRODUCT', 'PRODUCT', 'PRODUCT']]\n",
      "['\" УМНИЦА , КАША кукурузная, низкоаллерг ., с 4 мес ., ( 200г )\"', 'Каша овсяная с печёным яблоком']\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "test_texts = []\n",
    "for line in test_dataset:\n",
    "    test_labels.append(list(map(lambda x: x[1], line)))\n",
    "    test_texts.append(\" \".join(map(lambda x: x[0], line)))\n",
    "    \n",
    "print(test_labels[:2])\n",
    "print(test_texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2398"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### сохранить в файл транзакции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/kasha_pampers_test.tsv\", \"w+\") as fo:\n",
    "    for line in test_texts:\n",
    "        fo.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" УМНИЦА , КАША кукурузная, низкоаллерг ., с 4 мес ., ( 200г )\"\r\n",
      "Каша овсяная с печёным яблоком\r\n",
      "\" Nestle каша безмолочная мультизлаковая 5 злаков , с 6 месяцев , 200 г \"\r\n",
      "\" Remedia каша манная безмолочная пауч, с 5 месяцев , 200 г \"\r\n",
      "\" Русский продукт Геркулес овсяная каша ассорти: черника, малина, земляника , 6 шт по 35 г \"\r\n",
      "\" Каша молочная с 5 месяцев Агуша Овсянка , 10 шт по 200 г \"\r\n",
      "Каша гороховая с копченостями\r\n",
      "\" Каша Heinz молочная пшеничная с тыквой , 5 месяцев , 7 шт по 250 г \"\r\n",
      "КАША ХАЙНЦ Я БОЛЬШ ПАУЧ ГРЕЧ С 1Г 250Г\r\n",
      "\" Овсяная каша на кокосовом молоке , 200 гр .\"\r\n"
     ]
    }
   ],
   "source": [
    "!head /tmp/kasha_pampers_test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### получить предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 0 ns, total: 18.4 s\n",
      "Wall time: 18.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18590"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred_labels = []\n",
    "pred_text =[]\n",
    "for line in test_texts:\n",
    "    tmp = predict(line)\n",
    "    pred_labels.append(tmp[0])\n",
    "    pred_text.append(tmp[1])\n",
    "    \n",
    "len([item for sublist in pred_labels for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.22222222222223"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)/18 # скорость порядка 130-140 транзакций в секунду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tPrecision\tRecall\tF1\tTruePositive\tFalsePositiv\tFalseNegative\n",
      "ORDINAL\t\t0.951\t\t0.961\t0.956\t2064\t\t106\t\t83\n",
      "ORG\t\t0.951\t\t0.968\t0.959\t2414\t\t125\t\t80\n",
      "PRODUCT\t\t0.980\t\t0.977\t0.979\t4859\t\t97\t\t112\n",
      "MODEL\t\t0.946\t\t0.918\t0.932\t1547\t\t88\t\t138\n",
      "QUANTITY\t\t0.970\t\t0.957\t0.964\t3120\t\t96\t\t139\n"
     ]
    }
   ],
   "source": [
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "for y_test_l, y_pred_l in zip(test_labels, pred_labels):\n",
    "    calculate_match(y_test_l, y_pred_l)\n",
    "    \n",
    "labels=[\"ORDINAL\", \"ORG\", \"PRODUCT\", \"MODEL\", \"QUANTITY\"]\n",
    "print(\"Label\\t\\tPrecision\\tRecall\\tF1\\tTruePositive\\tFalsePositiv\\tFalseNegative\")\n",
    "for label in labels:\n",
    "    precision = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FP.get(label, 0))\n",
    "    recall = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FN.get(label, 0))\n",
    "    f1 = 2 * (precision*recall) / max((precision + recall),1)\n",
    "    print(\"%s\\t\\t%.3f\\t\\t%.3f\\t%.3f\\t%d\\t\\t%d\\t\\t%d\" % (label, precision, recall, f1, counter_TP.get(label, 0), counter_FP.get(label, 0), counter_FN.get(label, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_debug(true_values, pred_values):\n",
    "    for i, label in enumerate(filter(lambda v: v !=\"O\",true_values)): #stamza не показывает O\n",
    "        if len(pred_values) <= i:\n",
    "            counter_FN[label] += 1\n",
    "            #counter_FP[pred_value] +=1\n",
    "            continue\n",
    "            \n",
    "        pred_value = pred_values[i]    \n",
    "        if  label == pred_value:\n",
    "            print (f\"{i}:{label} == {pred_value}\")\n",
    "            counter_TP[label] += 1\n",
    "        else:\n",
    "            print(f\"{i}:{label} <> {pred_value}\")\n",
    "            counter_FN[label] += 1\n",
    "            counter_FP[pred_value] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\"', 'O'), ('Льняная', 'PRODUCT'), ('каша', 'PRODUCT'), ('кэроб,кокос,белый', 'PRODUCT'), ('лен', 'PRODUCT'), (\"'\", 'O'), ('Здоровка', 'ORG'), ('\\'\"', 'O')]\n",
      "[('Льняная', 'PRODUCT'), ('каша', 'PRODUCT'), ('кэроб,кокос,белый', 'PRODUCT'), ('лен', 'PRODUCT'), ('Здоровка', 'ORG')]\n",
      "-------------------------------------------------------------------------\n",
      "0:PRODUCT == PRODUCT\n",
      "1:PRODUCT == PRODUCT\n",
      "2:PRODUCT == PRODUCT\n",
      "3:PRODUCT == PRODUCT\n",
      "4:ORG == ORG\n",
      "-------------------------------------------------------------------------\n",
      "Label\t\tPrecision\tRecall\tF1\tTruePositive\tFalsePositiv\tFalseNegative\n",
      "ORDINAL\t\t0.000\t\t0.000\t0.000\t0\t\t0\t\t0\n",
      "ORG\t\t1.000\t\t1.000\t1.000\t1\t\t0\t\t0\n",
      "PRODUCT\t\t1.000\t\t1.000\t1.000\t4\t\t0\t\t0\n",
      "MODEL\t\t0.000\t\t0.000\t0.000\t0\t\t0\t\t0\n",
      "QUANTITY\t\t0.000\t\t0.000\t0.000\t0\t\t0\t\t0\n"
     ]
    }
   ],
   "source": [
    "counter_TP= Counter()\n",
    "counter_FN = Counter()\n",
    "counter_FP = Counter()\n",
    "\n",
    "index = 15 #11, 15\n",
    "print(test_dataset[index])\n",
    "print(list(zip(pred_text[index], pred_labels[index])))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "calculate_match_debug(test_labels[index], pred_labels[index])\n",
    "labels=[\"ORDINAL\", \"ORG\", \"PRODUCT\", \"MODEL\", \"QUANTITY\"]\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Label\\t\\tPrecision\\tRecall\\tF1\\tTruePositive\\tFalsePositiv\\tFalseNegative\")\n",
    "for label in labels:\n",
    "    precision = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FP.get(label, 0))\n",
    "    recall = counter_TP.get(label, 0) / (counter_TP.get(label, 1) + counter_FN.get(label, 0))\n",
    "    f1 = 2 * (precision*recall) / max((precision + recall),1)\n",
    "    print(\"%s\\t\\t%.3f\\t\\t%.3f\\t%.3f\\t%d\\t\\t%d\\t\\t%d\" % (label, precision, recall, f1, counter_TP.get(label, 0), counter_FP.get(label, 0), counter_FN.get(label, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
